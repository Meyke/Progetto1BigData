{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf500
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red91\green40\blue180;\red255\green255\blue255;
}
{\*\expandedcolortbl;;\csgray\c0;\cssrgb\c43529\c25882\c75686;\cssrgb\c100000\c100000\c100000;
}
\paperw11900\paperh16840\margl1440\margr1440\vieww23260\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \CocoaLigature0 Cluster emr con macchine tutte m3.xlarge\
\
Per connettermi al master node del cluster tramite ssh:\
ssh -i keypairMeyke.pem hadoop@<dns_pubblico-master>\
\
\
Per trasferire i file su cluster usa scp (secure copy. Vedere https://kb.iu.edu/d/agye):\
scp -i keypairMeyke.pem -r /Users/micheletedesco1/Desktop/<dns_pubblico-master>:~     (:~ indica il percorso (home/hadoop) del nodo remoto in cui vado a trasferire i file)\
\
NEL CASO NON SI CONNETTESSE CON SSH, MODIFICARE LE INBOUND RULES:\
https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-gs-ssh.html \
\
\
HADOOP JOB1 (cluster aws emr):\
\
hadoop jar job1/job1.jar job1.TopNPriceChanges /user/input/hist_price_1perc.csv /user/output -libjars job1/lib/log4j-1.2.17.jar\
hadoop jar job1/job1.jar job1.TopNPriceChanges /user/input/hist_price_10perc.csv /user/output -libjars job1/lib/log4j-1.2.17.jar\
hadoop jar job1/job1.jar job1.TopNPriceChanges /user/input/historical_stock_prices.csv /user/output -libjars job1/lib/log4j-1.2.17.jar\
\
\
HADOOP job2:\
hadoop jar job1/job1.jar job2.Job2Driver /user/input/hist_price_1perc.csv /user/input/historical_stocks.csv /user/output -libjars job1/lib/log4j-1.2.17.jar\
hadoop jar job1/job1.jar job2.Job2Driver /user/input/hist_price_10perc.csv /user/input/historical_stocks.csv /user/output -libjars job1/lib/log4j-1.2.17.jar\
hadoop jar job1/job1.jar job2.Job2Driver /user/input/historical_stock_prices.csv /user/input/historical_stocks.csv /user/output -libjars job1/lib/log4j-1.2.17.jar\
\
\
HADOOP job3:\
\
hadoop jar job1/job1.jar job3.Job3Driver /user/input/hist_price_1perc.csv /user/input/historical_stocks.csv /user/output -libjars Desktop/job1/lib/log4j-1.2.17.jar\
hadoop jar job1/job1.jar job3.Job3Driver /user/input/hist_price_10perc.csv /user/input/historical_stocks.csv /user/output -libjars Desktop/job1/lib/log4j-1.2.17.jar\
hadoop jar job1/job1.jar job3.Job3Driver /user/input/historical_stock_prices.csv /user/input/historical_stocks.csv /user/output -libjars Desktop/job1/lib/log4j-1.2.17.jar\
\
\
SPARK job1:\
spark-submit --class job1.TenBestAction9818 --master local[*] Desktop/job1/progetto1spark_2.11-0.1.jar /Users/micheletedesco1/Desktop/job1/hist_price_10perc.csv\
\
SPARK job2:\
spark-submit --class job2Daniele.Job2 --master local[*] Desktop/job1/progetto1spark_2.11-0.1.jar /Users/micheletedesco1/Desktop/job1/hist_price_1perc.csv /Users/micheletedesco1/Desktop/job1/historical_stocks.csv /Users/micheletedesco1/Desktop/job1/output\
\
SPARK job3:\
spark-submit --class job3.
\fs24 \cf3 \cb4 \expnd0\expndtw0\kerning0
\CocoaLigature1 ThreeYearTrend
\fs22 \cf2 \cb1 \kerning1\expnd0\expndtw0 \CocoaLigature0  --master local[*] Desktop/job1/progetto1spark_2.11-0.1.jar /Users/micheletedesco1/Desktop/job1/hist_price_1perc.csv /Users/micheletedesco1/Desktop/job1/historical_stocks.csv /Users/micheletedesco1/Desktop/job1/output}